=====================================================================
===                      REPLICATION PACKAGE                      ===
===                                                               ===
===   WORKFORCE COMPOSITION, PRODUCTIVITY, AND LABOR REGULATIONS  ===
===      IN A COMPENSATING DIFFERENTIALS THEORY OF INFORMALITY    ===
===                               BY                              ===
===            DANIEL HAANWINCKEL AND RODRIGO R. SOARES           ===
===                                                               ===
===                          JANUARY 2022                         ===
=====================================================================

This package includes code and clean data files necessary to replicate results in our paper. It also contains code to create the clean data files based on the original microdata, as well as information about how to obtain that data if necessary.

This readme file is divided in five sections. The first documents data sources used in the paper. The second describes and provides instructions for the programs in the ./Stata folder, which should be run first. The third section describes and provides instructions for the programs in the ./Matlab folder, which should be run last. The fourth section describes the main output files generated by the programs (stored in the ./Output folder) and links them to Tables and Figures in the paper. The last section contains references.

The package is provided under the Creative Commons Attribution 4.0 International Public License.


=====================================================================
===                           SECTION 1                           ===
===                  DATA AVAILABILITY STATEMENT                  ===
=====================================================================

=========================================
SUMMARY
=========================================
-- All of the raw data used by us is publicly available, though part of the data is not readily available for download on the internet.
-- This package includes cleaned versions of the data which are sufficient for replication.

=========================================
DETAILS FOR THE PME
=========================================
Data from the PME survey is publicly available at the website of the Brazilian Statistics Bureau (IBGE, "Instituto Brasileiro de Geografia e Estatística" - ibge.gov.br). The data was read and cleaned using code provided by the Data Zoom project, from the Economics Department at PUC-Rio (Pontifícia Universidade Católica do Rio de Janeiro). Data Zoom is currently available at http://www.econ.puc-rio.br/datazoom/english/

The data files generated by Data Zoom are included in this replication package (in the ./Stata/Panel folder). 

=========================================
DETAILS FOR THE BRAZILIAN CENSUS
=========================================
Census data is also created and maintained by IBGE. Currently, microdata for the years 2000 and 2010 are available for download at the IBGE website. The code also requires data from 1991; researchers interested in obtaining that data should reach out to the IBGE (there might be small financial costs associated with making that data available).

The clean, collapsed data at the microregion-year level, which is used in the regressions in Appendix H, is provided in this replication package (the .Stata/census_collapsed_data.dta file).

=========================================
DETAILS FOR THE ALMEIDA-CARNEIRO DATA
=========================================
We also use data from the paper "Enforcement of Labor Regulation and Informality", by Rita Almeida and Pedro Carneiro, published at the American Economic Journal:Applied Economics 4(3) from 2012. DOI: 10.1257/app.4.3.64 

The data can be downloaded at the article's website (https://www.aeaweb.org/articles?id=10.1257/app.4.3.64). It is also provided here for convenience (file AlmeidaCarneiroData.dta). The American Economic Association owns the copyright for that file. It is made available under a Creative Commons Attribution 4.0 International Public License.


=====================================================================
===                           SECTION 2                           ===
===                             STATA                             ===
=====================================================================

=========================================
SUMMARY
=========================================
The Stata folder includes programs that process data from the PME for the main exercises of the paper. It also includes code to perform the exercise in Online Appendix H using data from the Brazilian Census. 

This folder also includes a file "labor share.xls". This file contains our estimation of the standard error associated with the labor share target for estimation.

=========================================
SOFTWARE REQUIREMENTS
=========================================
The programs require Stata. The code was run on Stata MP versions 15.1 and 16.1. 

=========================================
HARDWARE REQUIREMENTS
=========================================
The programs are moderately time consuming, but do not require specialized hardware or a compute cluster. Processing the PME, including obtaining bootstrapped statistics, should take less than a day using modern personal computers.

Cleaning and collapsing data from the Census may take a few days but not more than a week. A computer with 16 GB of RAM is enough (but not 8 GB). Running the regressions on the clean, collapsed data set is very quick and requires very little memory.

=========================================
INSTRUCTIONS AND DESCRIPTION OF THE PROGRAMS
=========================================
To simplify the explanation of the code, I will list and describe programs separately according to two parts: processing data from the PME for the main exercises in the paper, and the robustness exercise in Online Appendix H using data from the Brazilian Census.

The full description of the procedures executed in these programs is provided in the online appendix.

=========================================
PART 1: PROCESSING THE PME
=========================================
Instructions: Run the runAll.do script, if replicating from scratch using PME microdata. Otherwise, no action is necessary, since the clean data files are available in the CleanData folder.

Description of files:

- runAll.do: This is the main file which creates input files for the Matlab procedures, calling getMoments.do and getNationalMoments.do.

- getMoments.do: This file processes the PME data and generates statistics as described in the online appendix. It is called several times in runAll.do. The main outputs are the files ../CleanData/pme_2003_regions.csv and ../CleanData/pme_2012_regions.csv. It also generates summary statistics used to generate Table 1 in the paper: ../CleanData/summaryTable1_2003.csv and ../CleanData/summaryTable1_2012.csv. Finally, it creates a series of bootstrapped statistics: the files ../CleanData/Bootstrap/pme_2003_regions_*.csv and ../CleanData/Bootstrap/pme_2012_regions_*.csv, where * is a number from 1 through 100.

- getNationalMoments.do: This file runs the IV estimation using data from Almeida and Carneiro. The main output is ../CleanData/national_2003.csv. It also generates bootstrapped statistics, ../CleanData/Bootstrap/national_2003_*.csv. NOTE: code in this file is based on the original code from Rita Almeida and Pedro Carneiro, for which we are grateful.

=========================================
PART 2: CENSUS REGRESSIONS (APPENDIX H)
=========================================
Instructions: Run census_dataCleaning.do, then census_collapse.do, then census_regreessions.do, is replicating from scratch using Census microdata. Otherwise, just run census_rehgressions.do.

Description of files:

- census_dataCleaning.do: This script reads the Census microdata using Data Zoom, process it, and saves an intermediate data file (census_person.dta, not included in this replication package).

- census_collapse.do: This script reads census_person.dta and executes procedures described in Appendix H to create a data set at the microregion-year level, census_collapsed_data.dta (included in this folder).

- census_regressions.do: This script runs the regressions and saves four files with the results in the ../Output folder: Tab_formal_noeduc.csv, Tab_formal_allc.csv, Tab_employed_noeduc.csv, and Tab_employed_allc.csv.


=====================================================================
===                           SECTION 3                           ===
===                             MATLAB                            ===
=====================================================================

=========================================
SUMMARY
=========================================
This folder includes programs that estimate the model, run counterfactuals, and create most of the tables and figures in the paper.

=========================================
SOFTWARE REQUIREMENTS
=========================================
The programs require Matlab. Parts of the results were obtained using Matlab 2016a, and others using Matlab 2020a.

=========================================
HARDWARE REQUIREMENTS
=========================================
The most computationally intensive parts of the code were run in the Acropolis Cluster at the University of Chicago.
- In Part 1 we used a single processor with 1 GB of RAM, and completed the calculations in less than a day. 
- In Part 2 we used 100 cores, each with 5 GB of RAM. It took about two weeks.
- In Part 3 we used 5 processors, each with 10 GB of RAM. It took less than a day.
- In Part 4 we used 100 cores, each with 5 GB of RAM. It took about a week.

=========================================
DATA REQUIREMENTS
=========================================
- These programs use the data files in the ../CleanData folder, which are generated by the programs in the ../Stata folder.

=========================================
INSTRUCTIONS AND DESCRIPTION OF THE PROGRAMS
=========================================
To simplify the explanation of the code, I will list and describe programs separately according to four main steps: data processing and reduction, estimation, counterfactuals, and bootstrap. Some programs perform basic functions that are used in multiple steps; I list those files at the end of the section.

The full description of the procedures executed in these programs is provided in the online appendix.

=========================================
PART 1: DATA PROCESSING AND REDUCTION
=========================================
Instructions: run the createMomentsFile.m script.

Description of files: 

- createMomentsFile.m: Runs all of the procedures in this part. The output is stored in the ../CleanData/moments_regions.mat file. It also saves ../Output/shareSkilledByGroup.xls.

- getMomentsAndV.m: This file describes some functions used to read PME and national data and convert them into the data format needed in estimation. It is called by createMomentsFile.m.

- getDataSummary.m: This file defines several functions that, in conjunction, perform the main data reduction described in the paper: transforming moments at the region-age-education level into region-skill level. It is called by getMomentsAndV.m.


=========================================
PART 2: ESTIMATION
=========================================
Instructions: Run the runEstimator.m function using as inputs the numbers 101 through 200. Run the script collectResultsEstimation.m to find which run was the best, then open the corresponding log file to see the optimal vector of choice variables. Finally, run the functions runEstimator_robustness_b.m  and runEstimator_sigma.m to re-estimate the model in different robustness scenarios.

Description of files: 

- runEstimator.m: ARuns the estimation procedure starting from different starting points (according to the input to the function). Depending on the input, it will estimate the model for the baseline level of gamma or an alternative value. It uses ModelEstimator.m. Its output is a log file ./estimationOutput/estimation_*.txt, where * is the id number. The log includes iteration-by-iteration results and displays the optimal vector of choice variables with high numerical precision.

- runEstimator_robustness_b.m and runEstimator_sigma.m: These files are alternative versions of the file above used to estimate the model under alternative assumptions about unemployment insurance or the bargaining power of workers in the informal sector. They were run using a single processor, with input 1 (meaning that the starting point was the optimal point found in the main estimation procedure).

- collectResultsEstimation.m: This script should be run after the estimation is complete. It will analyze results from log files corresponding to different starting points and show the best results for each gamma. Then, the corresponding log file can be opened to collect the optimal vector of choice variables.

NOTE: The file Model.m was slightly modified after the paper was conditionally accepted, in order to enable additional robustness exercises included in the final revision. We did not access to a high performance compute cluster at that time. Thus, the main estimation procedures where not run again. Because of this, and because of possible changes in Matlab versions, it is possible that replication of the estimation procedure will lead to slightly different results even if the random number generator seed is kept constant. We are sure, however, that these possible changes will be inconsequential for the conclusions of the paper.


=========================================
PART 3: COUNTERFACTUALS
=========================================
Instructions: Open the code for runMainCounterfactuals.m and make sure the "x" vectors in the starting lines correspond to the optimal vectors found in estimation, for the main specification and for all robustness exercises. Then, run that function with inputs 1 through 5.Next, run the outputSimulations.m script. Finally, run outputEquilibriumFigures.m.

Description of files: 

- runMainCounterfactuals.m: This Matlab function computes the counterfactual results, calling CounterfactualMaker.m. The input id determines which specific counterfactual exercise:
--- 1: Low value for gamma
--- 2: Main results with the intermediate level of gamma
--- 3: High value for gamma
--- 4: Robustness exercise, bargaining power in the informal sector
--- 5: Robustness exercise, unemployment insurance
Note that the optimal choice variables from the estimation stage are hard-coded in this function.
In each call, runMainCounterfactuals generates three files as outputs:
--- ./cleanOutput/estMain_*.mat: A Matlab data file with a ModelEstimator structure (which includes the estimated models for each region) and a Matlab structure with the value of the loss function, the national-level moments implied by the parameters, and a cell array with equilibrium characteristics for each region. This file is used as an input for CounterfactualMaker.m.
--- ./cleanOutput/cfMain_*.mat: Another Matlab data file with the output from CounterfactualMaker.m. These are two Matlab tables: pt, which has model parameters, and st, which has model statistics implied from different simulations.
--- ./cleanOutput/cfMainLog_*.txt: A log file.

- outputSimulations.m: This script creates Excel spreadsheets with the information necessary to create Tables 4 (except for standard errors), 5, 6, A.5, A.7, A.8, A.9, A.10, A.11, A.12, A.15, A.16, A.17, A.18, A.19. It also creates figures A.9 and A.10 (stored as ../Output/fig_fit.pdf and ../Output/fig_model2012.pdf, respectively).
The spreadsheets are created by processing the ./cleanOutput/cfMain_*.mat files. They are saved as ../Output/Tables_main.xls and ../Output/Tables_rob_***.xls, where *** is the name for a different robustness exercise. Each of these Excel files has three sheets: one with the fit, the second with changes from 2003 (including the baseline model and a several counterfactual simulations), and the third with the policy simulations. 

- outputEquilibriumFigures.m: A script that generates Figures 1 and A.3-A.7.

=========================================
PART 4: BOOTSTRAP
=========================================
Instructions: Run the function runBootstrapEstimation for inputs 1 through 100, preferably in parallel in a compute cluster. After that is done, do the same with the runBootstrapCounterfactuals function. Finally, run the outputParameters.m and outputSETables.m scripts.

Description of files: 

- runBootstrapEstimation.m: Re-estimates the model using bootstrapped data according to the id input, which denotes the specific resampling.

- runBootstrapCounterfactuals.m: Simulates counterfactuals using the model estimated from bootstrapped data according to the id input.

- outputParameters.m: A script that reads results from the bootstrap estimations and creates an Excel file with estimated parameters and their standard errors. It is stored in ../Output/parameters.xls. These numbers can be used to construct Table 3.

- outputSETables.m: A script that reads results from the bootstrap simulations and creates an Excel file with standard errors for several statistics. Is is stored in ../Output/standard_errors.xls. These numbers can be used to construct Tables A.13 and A.14, as well as the standard error columns in Table 4.


=========================================
AUXILIARY FILES USED IN MULTIPLE STEPS
=========================================
- Model.m: This file describes a Matlab class, Model. Each Model object contains parameters and includes several procedures used to perform calculations with the model, including solving for equilibrium, obtaining simulated statistics from an equilibrium, and plotting tools.

- ModelEstimator.m: This is another Matlab class whose goal is to estimate the model parameters given data at the region-skill level, along with the national moments. It uses Model.m.

- CounterfactualMaker.m: Another Matlab class whose goal is to run counterfactual exercises. It uses both Model.m and ModelEstimator.m.

- makeTablesFromModelStats.m: Function used to transform model simulations, as generated by CounterfactualMaker.m, into tables representing fit, validation, and counterfactuals. It also generates figures with fit and validation by regions.

- binarySearch.m: A function that performs simple binary search.

- saveFigure.m: Saves a Matlab figure into a pdf file.

- saveCellArrayToExcel.m: Saves a Matlab cell array into an Excel spreadsheet.


=====================================================================
===                           SECTION 4                           ===
===                   DESCRIPTION OF OUTPUT FILES                 ===
=====================================================================

All of these files are stored in the ./Output folder.

- fig_eq_***.pdf: These figures illustrate model equilibria for the six metropolitan regions in the PME. The file fig_eq_Recife.pdf contains Figure 1 in the paper. The remaining files are Figures A.3 through A.7 in the Appendix.

- fig_fit.pdf: Corresponds to Figure A.9 in the Appendix.

- fig_model2012.pdf: Corresponds to Figure A.10 in the Appendix.

- summaryTable1_2003.csv and summaryTable1_2012.csv: Descriptive statistics used to construct Table 1.

- parameters.xls: An Excel file containing estimated model parameters and their bootstrapped standard errors, needed to construct Table 3 in the paper. It is organized in the following way:
--- Sheet 1: All of the estimated model parameters, by region and skill.
--- Sheet 2: National averages of parameters that vary across regions.
--- Sheet 3: Standard errors associated with Sheet 1.
--- Sheet 4: Standard errors associated with Sheet 2.

- Tables_main.xls: An Excel file with data on fit, validation, and counterfactual exercises for the baseline specification.
--- Sheet 1: Data on model fit. Corresponds to the first two columns in Table 4.
--- Sheet 2: This table shows changes from 2003 through 2012 in the data, in the baseline model, and in several counterfactuals. Columns B and C correspond two the first two columns in the Validation part of Table 4. Columns E through I correspond to Columns (2)-(6) in Table 5 (not in the same order). Columns K through O correspond to Columns (2)-(6) in Table A.5 (not in the same order). Columns P and Q correspond to Columns (4) and (3) in Table A.19.
--- Sheet 3: Policy exercises from Table 6.

- standard_errors.xls: An Excel file with standard errors associated with target moments and simulated results from the model. It is organized in the exact same way as Tables_main.xls above.
--- Sheet 1: Standard errors associated with the model fit. Column B (Data) corresponds to the standard error column in part "Fit in 2003" of Table 4.
--- Sheet 2: Standard errors associated with changes from 2003 through 2012. Column B corresponds to the last column in Table 4. Columns E through I are used to create Table A.13.
--- Sheet 3: Used to construct Table A.14.

- Tables_rob_low_gamma.xls: This file is organized exactly as Tables_main.xls, but corresponds to the robustness exercise with low substitutability between skill levels. It is used to construct Tables A.15 and A.16.

- Tables_rob_high_gamma.xls: As above, but for high substitutability between skill levels. It is used to construct Tables A.17 and A.18.

- Tables_rob_unemp_ins.xls: As above, but for the robustness exercise with a different formulation of unemployment benefits. It is used to construct Tables A.7, A.8, and A.9.

- Tables_rob_sigma.xls: As above, but for the robustness exercise with a lower bargaining power in the informal sector. Used to construct Tables A.10, A.11, and A.12.

- Tab_formal_noeduc.csv, Tab_formal_allc.csv, Tab_employed_noeduc.csv, and Tab_employed_allc.csv: Microregion-level regression results in Table A.6.

- shareSkilledByGroup.xls: Corresponds to Table A.4.


=====================================================================
===                           SECTION  5                          ===
===                           REFERENCES                          ===
=====================================================================

Almeida, Rita, and Carneiro, Pedro. "Replication data for: Enforcement of Labor Regulation and Informality." Nashville, TN: American Economic Association [publisher], 2012. Ann Arbor, MI: Inter-university Consortium for Political and Social Research [distributor], 2019-10-12. https://doi.org/10.3886/E113830V1

Instituto Brasileiro de Geografia e Estatística - IBGE (2007). "Pesquisa Mensal do Emprego." https://www.ibge.gov.br/estatisticas/sociais/trabalho/9180-pesquisa-mensal-de-emprego.html?=&t=microdados

Instituto Brasileiro de Geografia e Estatística - IBGE (1992) "Censo demográfico 1991 : resultados preliminares" https://www.ibge.gov.br/estatisticas/sociais/saude/25089-censo-1991-6.html?edicao=25090&t=downloads.

Instituto Brasileiro de Geografia e Estatística - IBGE (2000) "Sinopse preliminar do censo demográfico : 2000" https://www.ibge.gov.br/estatisticas/sociais/saude/9663-censo-demografico-2000.html?edicao=9773&t=downloads

Instituto Brasileiro de Geografia e Estatística - IBGE (2011) "Sinopse do censo demográfico : 2010" https://www.ibge.gov.br/estatisticas/sociais/saude/9662-censo-demografico-2010.html?=&t=downloads